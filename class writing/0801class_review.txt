# 머신러닝
· 지도학습 - 분류(이진/다항분류) / 회귀
· 비지도학습

· 목표결정 → 데이터수집 → 데이터전처리 → 머신러닝 모델선택 → 학습 → 평가 → 적용

· 자체평가 하기 위해 데이터셋을 분리.
	- 학습을 위한 train data / 테스트를 위한 test data
	  train_test_split()함수 이용
	  기본 비율은 학습용 75%, 테스트용 25%
	- 지정된 열도 동일한 비율로 나누는 매개변수는 stratify
	- random_state = 0
	
· 캐글의 경우 train data가 train1(학습용), test1(테스트용)

#knn(k-Nearest Neighbors) model
· 데이터포인트와 가장 가까운 k개의 데이터를 찾아서 그 k개의 데이터가 가장 많이 예측하는 다수, 또는 평균으로 예측하는 알고리즘
	- 하이퍼파라미터 : 사용자가 지정하는 파라미터

#의사결정트리
· 구성 : 루트노드, 리프노드, Decision node
· 단점 : 트리의 깊이에 따라 과대적합, 과소적합 발생가능성 존재
· 노드가 분기하는 조건을 결정
	- 분류 : gini, entropy이용해 조건 결정
	- 회귀 : MSE이용해 조건결정

# 앙상블
· 여러 머신러닝모델을 연결해 더 강력한 모델을 생성
· Random Forest
	- 여러개의 트리를 사용
	- 약간씩 다른, 여러개의 트리로 구성
		데이터를 조금씩 다르게(중복복원추출)
		변수를 조금씩 다르게
	- 예측
		분류 : 10개의 트리가 예측하는 값의 다수로 예측
		연속 : 10개의 트리가 예측하는 값(target)의 평균으로 예측
· Gradient boosting