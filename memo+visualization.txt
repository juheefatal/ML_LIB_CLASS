<간단하게 정리한 관련 개념>

홀드아웃 검증(hold-out validation)
: 모든 학습 데이터를 학습 데이터와 검증 데이터로 완전히 분리하고 같은 검증 데이터를 모델 평가에 사용하는 기법

/*
model.fit()은 학습을 진행하면서 매 에포크마다 결과를 출력한다.
일반적으로 loss 값이 출력되고 
model.compile()에서 metrics를 accuracy로 지정하면 accuracy 값이 함께 출력됨.
*/

loss: 학습을 통해 구한 예측 값과 실제 값의 차이(=오차)를 의미
accuracy: 전체 샘플 중에서 정답을 맞춘 샘플이 몇 개인지의 비율(=정확도)을 의미

검증셋을 지정하면 val_loss가 함께 출력되는데 
이때 metrics를 accuracy로 지정하면 accuracy와 함께 val_accuracy 값도 출력됨. 

val_loss: 학습한 모델을 검증셋에 적용해 얻은 오차
val_accuracy: 검증셋으로 얻은 예측 정확도


<분석결과>
● loss그래프를 보면 학습 데이터에 대한 오차는 학습을 할수록 (에포크가 진행될수록) 줄어드는데,
실제 검증용 데이터에 대한 오차는 일정 수준 이상부터는 큰 차이가 없다.
● loss그래프를 보면 학습 데이터에 대한 오차는 학습을 할수록 (에포크가 진행될수록) 줄어드는데,
실제 검증용 데이터에 대한 오차는 일정 수준 이상부터는 큰 차이가 없다.
● adam [ min_loss = , max_acc = 0. % ] 
● RMSprop [min_loss = 5.0514, max_acc = 91.1% ]
● optimzer를 adam으로 돌렸을 때 보다 RMSprop으로 돌렸을 때 loss값이 더 작고, 
    굴곡의 변화도 더 적다. 그러나, 정확도 그래프에서는 adam이 더 정확도가 더 높고 
    결과적으로 adam이 더 높은 점수를 기록했다. 
    Inception v3 모델의 optimizer를 adam으로 확정하게 된 계기가 되었다.

<개선한 점>
1. 최초실행군의 그래프를 보고 학습률을 높여야겠다고 생각하여 epoch를 50으로 설정하였다. 
   결과적으로 loss값이 빠르게 줄어들어 작은 값으로 유지되는 것을 확인할 수 있다. 


<발표>
‘accuracy’, ‘val_accuracy’, ‘loss’, ‘val_loss’와 같은 키 값을 이용해서 데이터 훈련 과정을 시각화 해보았습니다.
왼쪽은 에포크에 따른 손실값 그래프, 
오른쪽에는 에포크에 따른 정확도 그래프입니다.

저희가 시도한 여러 기록들 중에
유의미한 결과값을 가진 세 가지 경우의 그래프를 선택해 분석해보았습니다.
저희가 선택한 코드인 Inception모델의 최초실행군 코드,
최고점을 기록했던 코드,
optimizer를 adam에서 rmsprop으로 바꿔서 돌려본 코드로 둘씩 묶어서 비교해보겠습니다.